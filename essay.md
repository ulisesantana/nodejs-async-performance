# C칩mo pas칠 un proceso en Node.js de 5 horas a 5 minutos

Hola! Soy Ulises Santana y trabajo como Full Stack Developer en Lean Mind donde ayudamos a otras empresas a hacer que sus proyectos de software sean m치s sostenibles. Soy de Gran Canaria, pero actualmente vivo en El Hierro desde donde trabajo de forma remota. Tengo una perrita llamada Mocha (en honor al nombre en clave de JavaScript cuando Brendan Eich empez칩 a trabajar en 칠l) y un gatete llamado Null. 

Hoy vengo aqu칤 a hablar de c칩mo pas칠 un proceso en Node.js de 5 horas a 5 minutos. Para ello vamos a empezar por lo b치sico, el contexto. Estaba trabajando para un cliente en un equipo de 5 personas, en el que las otras 4 se hab칤an incorporado en los 칰ltimos 3 meses, mientras que yo llevaba casi un a침o con el cliente. En este equipo mi rol era el de Senior Node.js Developer y era el 칰nico que ten칤a experiencia previa trabajando con Node.js. Aparte hab칤a otra persona con experiencia con JavaScript y Dart, lo cual hac칤a que le resultara f치cil adaptarse a los proyectos en TypeScript, que es el lenguaje en el que estaban todos los proyectos. Sin embargo, las otras tres personas del equipo ten칤an muy poca experiencia previa en JavaScript.

Por otro lado, est치bamos trabajando en las distintas partes de un motor de facturaci칩n que necesitaba ser adaptado para un cambio legislativo. Esto 칰ltimo significa que el deadline no se pod칤a mover, si el cambio no estaba hecho para esa fecha la empresa no pod칤a generar la facturaci칩n del siguiente mes. En caso de que no lleg치ramos le romp칤amos el cash flow. Suave, sin presi칩n.

Por concluir esta contextualizaci칩n:

- Se iba a rehacer un proyecto desde cero y hab칤an modificaciones en varios m치s.
- No todo el equipo controlaba la tecnolog칤a en la que se estaba trabajando.
- El deadline es fijo y cr칤tico, ya que rompemos el cash flow de la empresa en caso de retrasarnos.

## La calma antes de la tormenta

A Abraham Lincoln se le atribuye la siguiente frase: *Dame 6 horas para cortar un 치rbol y pasar칠 4 afilando el hacha*. Sab칤amos que iba a haber un cambio legislativo que conllevar칤an cambios en los proyectos, as칤 que desde 2 meses antes del deadline propusimos refactorizar los proyectos y uno en concreto solicitamos rehacerlo desde 0, ya que en ese entonces era realmente un prototipo que funcionaba, pero costaba mantener y con el cambio legislativo se iba a hacer m치s insostenible. Vamos a llamar a este proyecto el *Proyecto Le침ador*.

![](assets/lumberjack.jpeg)

En Lean Mind por regla general trabajamos haciendo pair o mob programming, por lo que nadie nunca est치 solo y as칤 facilitamos que el c칩digo sea m치s sostenible y que tanto la autor칤a del c칩digo como el conocimiento se comparta. Sin embargo, como ten칤amos 5 proyectos que actualizar decidimos dividirnos lo m치ximo posible para poder abarcar al menos 3 proyectos a la vez y poder tener los cambios lo antes posible. Eso sale a 2 personas por proyecto y una persona sola. Esa persona que se qued칩 sola fui yo y estuve a varias bandas asistiendo a los diferentes equipos a la par que trabajaba en el proyecto en el que me tocaba. 

Esta situaci칩n hizo que por falta de tiempo descuidara el proceso de code review y simplemente me centrara en resolver las dudas del equipo sobre todo en dominio, ya que recuerdo que el resto del equipo llevaba solo 3 meses con el cliente y el dominio del negocio ten칤a una curva de asimilaci칩n de al menos 6 meses. Adem치s, como hac칤amos TDD, si los test pasan y reflejaban bien las especificaciones de negocio no hab칤a de qu칠 preocuparse. 

El *Proyecto Le침ador* fue llevado a cabo por miembros del equipo que no ten칤an mucha experiencia previa en JavaScript y ninguna en TypeScript. Esto no supon칤a a priori ning칰n problema porque ya llevaban tres meses haciendo pair o mob programming con miembros del equipo que s칤 ten칤an experiencia previa y estas mismas personas hab칤an hecho aportaciones a los diferentes proyectos en TypeScript. Simplemente ped칤an ayuda o consejo cuando lo necesitaban y se les asist칤a.

La realidad es que el salto de calidad era m치s que evidente. No vi el proyecto en su estado final directamente, sino que lo vi evolucionar a lo largo de las semanas y realmente era mucho m치s claro en su prop칩sito y no hab칤a sorpresas en la implementaci칩n. Yo hab칤a sido parte del equipo que hab칤a hecho ese prototipo 9 meses atr치s y la verdad es que hab칤a ciertas partes que para m칤 eran un pel칤n oscuras, que no terminaba de entender c칩mo funcionaban o cu치l era su prop칩sito final.

Estaba muy orgulloso de lo que el equipo hab칤a conseguido, realmente era un proyecto mucho m치s sostenible, eliminando sorpresas. Sin embargo, cuando estaba terminado e hice una 칰ltima revisi칩n algo m치s extensa con el equipo ve칤a algunos flujos de datos que ten칤an toda la pinta de bloquear el Event Loop, perdiendo performance. De todos modos, en ese momento no le di importancia, simplemente pas칠 al siguiente paso que ten칤amos planeado: hacer una prueba comparando el prototipo original con el *Proyecto Le침ador* para ver si realmente bajo el mismo input hab칤a el mismo output y de paso ver c칩mo se comportaba en performance. 

El prototipo original bas치ndose en un set de datos de unos cientos de miles de registros era capaz de hacerlo todo en unos 7 minutos. Con el mismo set de datos prob칠 con el *Proyecto Le침ador* y el resultado fue que tard칩 nada m치s y nada menos que **5 horas 7 minutos y 54 segundos.** Estamos hablando de que tardaba 44 veces m치s. El proceso real en producci칩n tardaba cada noche unos 40 minutos, por lo que si mand치bamos esto a producci칩n el nuevo proceso tardar칤a unas 29 horas y 20 minutos, esta p칠rdida de performance era inasumible. En ese momento mi yo interno era algo as칤:

![](assets/gifs/coffin-dance.gif) 

Por meter m치s le침a al fuego [쯟o pillas? Le침a, *Proyecto Le침ador* 游뱎], esto pas칩 a unos 10 d칤as del deadline, 10 d칤as naturales. No pod칤amos replantear el proyecto, hab칤a que optimizarlo en menos de una semana, adem치s de que hab칤a m치s cosas en la parrilla. En esta situaci칩n, por un lado me motivaba a m칤 mismo pensando cosas del tipo *Llevo toda mi vida prepar치ndome para este momento, los talleres sobre asincron칤a en Node.js con Matteo Collina y James Snell van a dar sus frutos* [Por cierto, un saludo desde aqu칤 a Matteo Collina y James Snell]. Sin embargo, otra parte de m칤 era una mezcla de esto:

![](assets/gifs/sheldon-bag.gif)
![](assets/gifs/pickle-rick.gif)

La realidad es que entr칠 en modo p치nico y empec칠 a refactorizar el proyecto y tratar de mejorar en performance todo lo que pod칤a. No cambi칠 nada de l칩gica, me limit칠 a cambiar el flujo de datos as칤ncrono, que era mayormente todo lo que tuviera que ver con leer o escribir en base de datos.

## Campeando la tormenta

Tras este refactor vi ciertos patrones que quiero remarcar y mostrar:

### 1. Evita async innecesarios

Los async cuando los ponemos en una funci칩n, estamos autom치ticamente haciendo que devuelva una promesa, y eso hay que gestionarlo de m치s. (_Demo async-await/useless-async_)

* Ten en cuenta que cada funci칩n as칤ncrona de por s칤 devuelve una promesa. Si devuelves una promesa JavaScript tiene que gestionarlo. Comentar ejemplo de jest o incluso hacer un benchmarking.

### 2. Evita los await dentro de los bucles.

Imagina que tienes una tarea que hacer que sea en base a una lista de IDs tienes que recuperar informaci칩n de una API. Por limitaciones t칠cnicas no puedes pasarle a la API la lista de IDs, sino que tienes que hacer una llamada por cada ID. 쮺u치l es la primera idea que se nos viene a la cabeza? Probablemente un bucle, apesta a bucle. La implementaci칩n podr칤a ser algo as칤:

```javascript
async function fetchUserListInfo(ids) {
  const values = []
  for (id of ids) {
    values.push(await fetchUserInfo(id))
  }
  return values
}
```

Parece sencillo y adem치s si lo probamos veremos que funciona. Consigue la informaci칩n de todos los usuarios sin problemas. 쯉in problemas? Ese await dentro del `for` fuerza a que se termine de completar cada promesa antes de procesar la siguiente. Esto significa que si de media la API tarda en responder 50ms y tenemos 100 IDS que procesar, tardaremos unos 5 segundos en realizar la tarea. No es que sea un drama, pero si hacemos este ligero cambio la cosa cambia bastante:

```javascript
function fetchUserListInfo(ids) {
  const values = []
  for (id of ids) {
    values.push(fetchUserInfo(id))
  }
  return Promise.all(values)
}
```

Aqu칤 vemos hay tres sutiles diferencias:
1. La funci칩n ya no es as칤ncrona, aunque s칤 que devuelve una promesa.
1. Dentro del for ya no hacemos un await
1. Devolvemos un Promise.all en vez de los valores como hac칤amos antes.

La gran diferencia de esta soluci칩n es que dentro del bucle no resolvemos las promesas, sino que simplemente las a침adimos a nuestro array en estado *Pending*. Cualquier funci칩n que devuelva una promesa la devuelve en este estado que hasta que no uses `await` o `.then` no estar치 *fulfilled* o *rejected*. Puedes verlo como el experimento del gato de Schrodinger, hasta que no abres la caja no sabes si el gato est치 vivo o muerto. A las promesas les pasa algo parecido, hasta que no las resuelves est치n en estado *pending* y una vez resueltas pueden estar *fulfilled*, que es cuando se ha resuelto satisfactoriamente, o *rejected* que es cuando ha habido alg칰n error.

Volviendo a la soluci칩n, vemos que las promesas no se resuelven, sino que se almacenan directamente en estado *Pending* y la funci칩n al devolverlas, las resuelve todas *a la vez*. Esto hace que ahora la tarea se haga mucho m치s r치pido, tardando lo que tarde en responderse la llamada a la API m치s lenta. 

Tengo por aqu칤 otra demo en la que usamos el mismo c칩digo, lo 칰nico que cambia es la tarea en s칤, que lo 칰nico que hace es esperar un milisegundo y devolvernos los 4 primeros caracteres del ID, simplemente por hacer algo. Lo que vamos a ver es cuanto tarda cada una de las soluciones ejecutando esta tarea para una lista de 100 IDS y lo va a hacer 1000 veces para que podamos ver si realmente hay una diferencia de performance o no.

### 3. Usa Promise.all siempre que puedas, el Promise.allSettled tambi칠n existe

(_Demo best-practices/promise-all_)
(_Demo best-practices/promise-all-settled_)

### 4. S칠 consciente de cuantas promesas est치s gestionando

Si no sabes cu치ntas promesas vas a tener en un Promise.all usa p-map y limita la concurrencia. 

Recordar que la version 5 pas칩 a ser tipo modules y nosotros nos quedamos en la 4.

### 5. Los async iterators pueden ser maravillosos
Hasta ahora el 칰nico uso que les he dado es para leer en lotes de la base de datos. Sin embargo, en este caso de uso es maravilloso.

### 6. Cachear queries

Esto no es exclusivo de Node.js, pero era algo que no est치bamos haciendo y que pod칤a ayudar, ya que hab칤a ciertos datos que no cambiaban durante la ejecuci칩n y que no ven칤a mal tenerlos cacheados. 

Lo que s칤 es exclusivo de Node.js es c칩mo cachear esta clase de datos. No cacheas el valor, sino la promesa que te devuelve. Ya despu칠s cuando coges la promesa cacheada la resuelves y ya.

(_Demo best-practices/cached-promises_)

### 7. Haz caso de los warnings

En la consola al ejecutar el proceso me sal칤a esto:
    
```shell
(node) warning: possible EventEmitter memory leak detected. 11 listeners added. Use emitter.setMaxListeners() to increase limit.
```

Yo pensaba *Meh, es un warning*. En una primera instancia simplemente hice lo que me dec칤a y aument칠 los listeners. Sin embargo, hasta que no me dediqu칠 a limpiar los listeners a medida que los usaba no not칠 la mejora de performance. No era un posible memory leak, era un memory leak en toda regla.

El problema era que hab칤a event handlers que se estaban creando continuamente con cada conexi칩n que se solicitaba al pool de conexiones a la base de datos, pero que no se estaban eliminando, pudiendo ser el causante del memory leak. Tras implementar un fix en el que cada vez que se devuelve una conexi칩n al pool se limpian los event handlers vimos una mejor칤a en la performance, bajando 4 veces el tiempo de ejecuci칩n.  

## Resultado  

Con todas estas mejoras en el *Proyecto Le침ador* lo volvimos a ejecutar con el mismo set de datos y en esta ocasi칩n tard칩 **04:52**, siendo incluso m치s r치pido que el prototipo. 

![](assets/gifs/fuck-yeah-dude.gif) 

Y ya por estar completamente seguros de que hab칤a una mejora, ejecutamos una prueba con un set de datos semejante al que se enfrentaba en producci칩n d칤a a d칤a, que eran millones de registros en la base de datos. En este caso el resultado qued칩 claro:

- Prototipo: 41:29 minutos  
- *Proyecto Le침ador:* 31:56 minutos

Aparte de haber mejorado la sostenibilidad del proyecto, hab칤amos mejorado la performance m치s de un 20%. Y todo esto llegando al deadline.

## Otras cosas que he visto en otros proyectos y que tampoco recomiendo que hagas

* Poner ejemplo que es pan con pan y una pulga en medio. (_Demo async-await/dont-try-this-at-home_)
* Mezclar async/await con Promises


## Cosas que aprend칤

Tras esta experiencia saqu칠 un par de cosas en claro:

* **Forma a tu equipo**, comparte el conocimiento. Busca tiempo en la semana para poco a poco ir form치ndolo. En mi experiencia el mob programming ayuda bastante, pero no es suficiente. Algunos conceptos necesitas interiorizarlos y para eso lo mejor es hacer katas o tener formaciones con objetivos concretos. Al principio es bastante duro preparar esta clase de formaciones, pero a medida que las tengas podr치s reusarlas a medida que entren personas nuevas o si cambias de proyecto puedes formar a ese nuevo equipo.
* **No necesitas un ej칠rcito de Seniors aka personas experimentadas en X tecnolog칤a**. Con que haya un Senior que controle la tecnolog칤a es suficiente, pero la responsabilidad tecnol칩gica no debe recaer enteramente en 칠l, por lo que debe compartir el conocimiento.
* **S칠 prescindible.** Si eres prescindible no ser치s el cuello de botella. Ojo, prescindible que no innecesario. Con esto quiero decir que no seas cr칤tico por conocimiento. Trata siempre de compartir tu conocimiento con el equipo.
